# LMSR Implementation Guide for Binary Prediction Markets in Solidity

Modern prediction markets face a critical liquidity challenge that LMSR was designed to solve: providing guaranteed liquidity from day one without requiring a deep order book. For a system where markets are automatically created based on raffle thresholds, **the Logarithmic Market Scoring Rule offers bounded, predictable losses** (exactly **b × ln(2) ≈ 0.693b** for binary markets), making treasury budgeting straightforward. However, recent production deployments reveal that **pure LMSR is losing ground to simpler alternatives** like Constant Product Market Makers (CPMM), with Augur abandoning LMSR entirely and Polymarket migrating to order books after experiencing LMSR's capital inefficiency firsthand. The evolution from LMSR to Liquidity-Sensitive LMSR (LS-LMSR) represents the most promising path forward, **eliminating guaranteed losses while maintaining automatic liquidity**, though no major platform has deployed it in production yet. This report synthesizes implementations from Gnosis, Augur, and emerging research to provide actionable guidance for building LMSR-based markets in 2025.

## The mathematical foundation and its computational challenges

The LMSR cost function **C(q) = b · ln(Σe^(qi/b))** encodes an elegant property: it guarantees bounded loss while providing continuous liquidity at all price points. For binary markets, this simplifies to **C(q₁, q₂) = b · ln(e^(q₁/b) + e^(q₂/b))**, where q₁ and q₂ represent net quantities sold for each outcome. The marginal price emerges naturally as **P₁ = e^(q₁/b) / (e^(q₁/b) + e^(q₂/b))**, ensuring prices always sum to exactly 1.0, maintaining direct probability interpretation. Trading cost follows from the difference in cost functions: to buy Δq shares, users pay **C(q_new) - C(q_old)**. This mathematical elegance comes with computational complexity—exponentials and logarithms are expensive operations in the EVM, costing approximately 25,000 gas per LMSR calculation.

Gnosis pioneered the most gas-efficient approach by using **binary logarithms (log₂) instead of natural logarithms**, exploiting the mathematical equivalence ln(x) = log₂(x) / log₂(e). This reduces computational costs by 30-40% since binary operations align perfectly with the EVM's word size. Their implementation in the conditional-tokens-market-makers repository demonstrates critical numerical stability techniques, particularly the **offset method for preventing overflow**: before calculating exponentials, they factor out the maximum value across all outcomes, then add it back at the end. This single technique enables markets to operate even with large position imbalances that would otherwise cause transaction reverts.

The choice of fixed-point math library fundamentally impacts both gas costs and precision. **ABDKMath64x64 emerges as the clear winner for LMSR implementations**, using a 64.64 format (64 bits integer, 64 bits fractional) that delivers approximately 600 gas for logarithm operations—the most efficient available. Gnosis uses a variant called Fixed192x64Math with 192.64 format for additional precision. PRBMath offers an alternative with 59.18 decimal format that's more intuitive for token calculations (18 decimals matching ERC20 standards), but runs approximately 4x slower for exponential operations. For LMSR specifically, ABDKMath64x64's binary format and gas efficiency outweigh PRBMath's decimal convenience, though teams already using PRBMath elsewhere may prefer consistency across their codebase.

A simplified implementation using ABDKMath64x64 demonstrates the core pattern. The liquidity parameter derives from funding via **b = F / ln(2) ≈ F / 0.693**, meaning a $100 market requires approximately $69.31 in locked capital. The cost function calculation involves three exponential operations, one addition, and one logarithm—computationally intensive but unavoidable. Gas optimization focuses on storage packing (reducing 5 slots to 2 saves 60,000 gas), custom errors instead of require strings (90% cheaper), and caching storage reads in memory since SLOAD costs 2,100 gas while MLOAD costs just 3 gas. The complete trade operation typically consumes **100,000-150,000 gas**, competitive with Uniswap V2's 127,000 gas baseline.

## Production implementations reveal critical lessons

Gnosis built the most mature LMSR implementation for prediction markets, with their conditional-tokens-market-makers repository serving as the de facto reference. Their architecture separates concerns elegantly: the Conditional Token Framework (CTF) handles outcome token creation and management, while LMSRMarketMaker implements pricing logic. Markets receive funding F upfront, automatically calculating **b = F / ln(n)** where n equals the number of outcomes. For binary markets, this means every $69.31 of funding provides approximately 100 units of liquidity depth. Their calcNetCost function implements the full LMSR formula with overflow protection, while calcMarginalPrice provides instant price quotes without state changes, enabling free off-chain price checks.

Gnosis's production deployment through Omen (formerly managed by DXdao) revealed **real-world parameter choices clustered around b = 50 as the "Goldilocks" value** for medium-sized markets. Their documented lessons include several disadvantages that led to platform evolution: capital inefficiency requiring significant upfront funding, poor response to market shocks (like candidates dropping out of races), and initial probability constraints forcing equal starting probabilities that create immediate arbitrage opportunities. The platform now offers both LMSR and CPMM options, with users gravitating toward CPMM for better capital efficiency. The new Presagio platform (Omen 2.0), backed by GIP-113, continues LMSR support but integrates AI agents for forecasting, acknowledging that pure LMSR needs augmentation for competitive performance.

Augur's journey proves particularly instructive. **Augur V2 abandoned LMSR entirely**, switching to 0x Protocol orderbooks that proved too expensive at 700,000 gas per trade versus Uniswap's 4,000 gas. Augur Turbo then migrated to **Balancer V1 pools** on Polygon, choosing simpler constant product formulas over LMSR's theoretical advantages. Their technical roadmap explicitly states that lower transaction costs and simpler UX outweighed LMSR's bounded loss guarantees. This represents a significant verdict from a major platform: after extensive evaluation, they concluded LMSR's complexity didn't justify its benefits for production deployment. Polymarket followed a similar arc, initially using LMSR before migrating to a Central Limit Order Book (CLOB) for superior capital efficiency and deeper liquidity.

The pattern across production systems reveals that **pure LMSR rarely survives contact with real users and competitive markets**. Platforms either augment it significantly (Gnosis adding CPMM options), abandon it for simpler mechanisms (Augur, Polymarket), or remain in play-money contexts where guaranteed losses are acceptable (Microsoft, Yahoo internal markets). No major platform has implemented the theoretically superior LS-LMSR variant despite academic recommendations dating to 2013, suggesting either hidden implementation barriers or insufficient perceived benefits over simpler alternatives.

## Choosing the liquidity parameter determines everything

The liquidity parameter b controls market depth with mathematical precision: **maximum loss equals b × ln(n)**, which for binary markets simplifies to **0.693b**. A market with b = 100 faces maximum loss of $69.31 regardless of trading patterns—this bounded loss makes treasury planning straightforward. The relationship between b and price sensitivity follows a simple principle: larger b values create deeper markets where prices change slowly, while smaller b values create shallow markets where prices react sharply to trades. Cultivate Labs discovered this empirically through their AlphaCast platform, testing b values of 15, 50, and 250. With **b = 250, prices moved only ~1% when buying 10 shares** (37.6% to 38.6%), deemed too sticky for effective price discovery. At **b = 15, the same trade moved prices ~26%**, creating excessive volatility. Their **optimal value of b = 50 moved prices ~4%**, balancing liquidity and responsiveness.

The funding relationship **b = F / ln(n)** determines capital requirements. For binary markets where ln(2) ≈ 0.693, creating a market with b = 50 requires **F ≈ $34.66**, while b = 100 requires **F ≈ $69.31**, and b = 250 requires **F ≈ $173.29**. These represent locked capital that remains unavailable until market resolution, creating significant opportunity costs. Scaling to multiple markets multiplies these requirements: running 100 markets simultaneously with b = 50 each locks **$3,466** in capital that could otherwise generate yield elsewhere. This capital inefficiency drove many platforms away from LMSR, particularly when competing against CPMM alternatives that allow dynamic liquidity provision and removal.

Price impact and slippage scale inversely with b. In a binary market starting at equilibrium (both outcomes at 50%), buying 100 shares in a b = 100 market costs approximately **$62.01** (average price $0.62 per share) and moves the marginal price to **73.1%**. The same trade in a b = 250 market costs less with reduced slippage, while in a b = 10 market the slippage becomes severe. This non-linear relationship means that at very low outstanding quantities, even small trades can push prices toward extremes. A single bet might cost 90 cents even when the marginal price shows 50%, particularly problematic during market initialization before sufficient trading volume accumulates.

The static versus dynamic b parameter debate centers on LS-LMSR's core innovation: **b(q) = α × Σqi**, where liquidity automatically scales with trading volume. Initial advantages appear compelling—markets start with near-zero capital requirements and bounded loss, growing liquidity only as activity warrants. Mathematical analysis proves that maximum loss equals C(q₀) for any initial state, and the market maker can achieve outcome-independent profit when markets resolve without prices converging to certainty. The formula bounds price sums between 1 and 1 + αn×ln(n), meaning for binary markets with α = 0.05, prices sum to between 1.00 and 1.07. However, this **breaks translation invariance**—prices no longer sum to exactly 1, eliminating direct probability interpretation. Despite theoretical superiority and academic endorsement from CMU researchers, **no major platform has deployed LS-LMSR in production**, suggesting implementation complexity or user experience concerns outweigh efficiency gains.

## Liquidity provisioning strategies determine sustainability

Initial liquidity seeding for LMSR markets requires upfront capital commitment based on the funding formula. For a new binary market with b = 50, the market creator must lock **$34.66** immediately. This capital remains locked for the entire market duration, creating opportunity cost equal to potential yield elsewhere. Treasury-funded models dominate existing LMSR implementations because the mechanism's bounded loss and single-funder design make third-party liquidity provision awkward. Unlike Uniswap-style pools where multiple LPs contribute proportionally, LMSR markets typically receive all funding from one entity—the platform treasury or market creator—who absorbs the guaranteed maximum loss.

User-funded LMSR models face fundamental challenges. Allowing multiple LPs to contribute to a single shared b parameter requires complex accounting to track proportional exposure, and creates "last mover disadvantage" where late contributors subsidize existing traders' positions. Running parallel LMSR instances for each LP fragments liquidity, undermining the mechanism's primary advantage. Some platforms explored issuing LP shares representing proportional market maker positions, but this introduces additional complexity around fair entry/exit pricing. The zero-sum nature of prediction markets (one outcome wins, others lose) means LP positions face **"near-total loss" risk rather than impermanent loss**, making user LP recruitment significantly harder than for trading pair AMMs where both sides retain value.

Capital efficiency strategies center on liquidity recycling and parameter optimization. When markets resolve, the market maker collects all non-winning outcome tokens (now worthless) and pays out winning tokens. Net payout equals **qi - C(q)** where i is the winning outcome. If this value is negative, the market maker profited; if positive, they lost (up to the known maximum). Unused capital from resolved markets can immediately redeploy to new markets, reducing total capital lock. Statistical diversification across multiple uncorrelated markets allows a single capital pool to serve many markets simultaneously—if most markets remain balanced, peak capital requirements stay well below the sum of individual maximum losses. Gnosis's conditional token framework enables this through composable market structures where outcome shares from one market serve as collateral for conditional markets, **reusing capital across multiple layers**.

The optimal b parameter selection for capital efficiency depends on expected trading volume. A commission-based approach sets **α = v / (n × ln(n))** where v represents the target maximum commission percentage. For a 10% commission target in binary markets, α ≈ 0.144. This translates to specific b values based on anticipated volume. Low-activity markets (10-50 expected trades) benefit from **b = 10-30** to ensure trades meaningfully move prices. Medium-activity markets (50-500 trades) work well with **b = 50-100**, matching Cultivate Labs' findings. High-activity markets (500+ trades) can support **b = 150-500** while maintaining adequate price discovery. Multi-tier approaches assign b values automatically based on market metadata, allocating capital proportionally to expected importance and activity.

## Contract architecture patterns for production deployment

The factory pattern with modular components represents the overwhelmingly preferred architecture for prediction market systems. This approach deploys a MarketFactory contract that creates individual LMSRMarketMaker instances on demand, each tracking its own state and liquidity. The factory maintains a registry mapping condition IDs to market addresses, enabling efficient lookup and iteration. Gnosis, Polymarket (initially), and most academic implementations use this pattern because it offers **scalability without contract bloat**, saves approximately 1 million gas per deployment versus proxy patterns, and allows component swapping (different AMM algorithms, oracle systems, or token standards) without disrupting existing markets.

Integration with raffle-triggered market creation requires event-driven architecture with careful access control. When a raffle reaches its participation threshold, the raffle contract calls a market creation function on the factory, passing relevant metadata like description, resolution time, and funding amount. This integration point needs **whitelist authorization** to prevent spam market creation, **rate limiting** to bound costs, and **sufficient gas reservation** (approximately 500,000 gas minimum) to complete the transaction. Chainlink Automation provides an alternative approach where the checkUpkeep function monitors raffle balance, and performUpkeep triggers market creation when conditions satisfy, fully decentralizing the trigger mechanism without requiring direct contract calls.

Market lifecycle management follows five distinct states: CREATED (market deployed but not yet funded), TRADING (active trading period), CLOSED (trading ended, awaiting oracle resolution), RESOLVED (oracle determined outcome), and SETTLED (all positions claimed, market finalized). State transitions enforce strict sequencing—markets cannot resolve without closing first, and settlement requires resolution. The trading phase implements the core LMSR logic with calcNetCost computing trade costs from state changes, and safety checks enforcing slippage limits via maxPrice parameters and deadline timestamps for transaction expiry. Proper implementation uses the **nonReentrant modifier** since external token transfers during trades create reentrancy attack surface.

Oracle integration determines resolution reliability and cost. **UMA's Optimistic Oracle V3 emerges as the recommended choice for general events**, offering economic security through bonding (asserters post collateral), built-in dispute resolution (anyone can challenge incorrect assertions within the liveness period), and cost-effectiveness (approximately 0.1 LINK equivalent per resolution). The assertTruth function accepts natural language claims like "Market [id] resolved to outcome 1" along with bond amount, liveness period (typically 2 hours), and callback recipient. Upon resolution, the oracle calls assertionResolvedCallback with the assertion ID and truthfulness boolean, triggering final market state updates. Chainlink Price Feeds suit price-based markets (like "Will BTC exceed $100k?"), offering continuous price updates with staleness checks via latestRoundData. Multi-oracle consensus adds security for high-stakes markets by requiring 3+ independent oracle confirmations before finalizing resolution, though this increases costs proportionally.

Access control follows role-based patterns using OpenZeppelin's AccessControl library. Typical roles include MARKET_CREATOR_ROLE for authorized market factory callers, RESOLVER_ROLE for entities permitted to initiate resolution, PAUSER_ROLE for emergency market halting, and DEFAULT_ADMIN_ROLE for role management itself. Critical operations like fee changes or liquidity parameter adjustments benefit from timelocks, requiring a two-step process where changes queue with a delay (typically 2 days) before execution, giving users time to exit if they disagree with governance decisions. This pattern has become standard across DeFi protocols and prevents sudden rug pulls or hostile parameter changes.

## Handling edge cases and preventing attacks

Prices near 0 or 1 create numerical instability in LMSR calculations, as exponentials approach infinity and logarithms approach negative infinity. The solution combines bounded pricing and log-space calculations. **Bounded pricing enforces minimum and maximum prices** (typically 0.1% and 99.9%), preventing the cost function from reaching true extremes where floating-point arithmetic breaks down. When raw LMSR calculation returns a price outside these bounds, the contract clamps it to the nearest valid value. This introduces small arbitrage opportunities at price extremes but maintains system stability—a worthwhile trade-off.

Log-space calculations handle large quantity imbalances by factoring out the maximum quantity before computing exponentials. Instead of calculating e^(q₁/b) + e^(q₂/b) directly, the algorithm finds maxQuantity = max(q₁, q₂), then computes e^((q₁-maxQuantity)/b) + e^((q₂-maxQuantity)/b), ensuring the exponential arguments stay moderate. After summing, it adds maxQuantity back to the final result. This technique **prevents overflow even when q₁ - q₂ exceeds 100**, a scenario that would otherwise exceed solidity's number representation limits and revert all transactions. Gnosis's production code implements this offset method throughout their LMSR calculations.

Rounding and precision strategies universally follow one rule: **always round in favor of the protocol**. When calculating user payouts, round down using integer division truncation. When calculating fees owed, round up using the formula (amount × feeRate + WAD - 1) / WAD. When computing trade costs, use mulDivUp to ensure the market maker collects slightly more than the mathematical minimum. These micro-optimizations prevent attackers from extracting value through repeated small transactions that exploit rounding in their favor. Over thousands of trades, improper rounding could drain liquidity pools entirely. Additionally, preserve precision by multiplying before dividing—calculating (a × c) / b rather than (a / b) × c avoids unnecessary precision loss from early division.

Front-running prevention requires multi-layered defense. **Slippage protection via maxPrice parameters** allows users to specify acceptable execution prices, causing transactions to revert if front-runners push prices beyond thresholds. Commit-reveal schemes split trades into two steps: first commit a hash of the trade details, then reveal actual parameters after a delay (typically 1 minute minimum). This prevents front-runners from seeing trade contents in the mempool, though at the cost of requiring two transactions. Batch auctions collect orders for a fixed period (15 seconds), then execute all simultaneously at a single clearing price, completely eliminating sandwich attacks since all trades execute atomically at identical prices. Gas price limits (via require(tx.gasprice <= maxGwei \* 1 gwei)) prevent high-gas front-running but interfere with legitimate urgent transactions during network congestion.

Market manipulation resistance implements multiple safeguards. **Liquidity-based trade limits** cap individual trades at a percentage of total liquidity (typically 10%), preventing single trades from dominating price discovery. Price impact limits reject trades that move prices more than a threshold percentage (typically 5%), forcing large orders to split across multiple transactions. Time-weighted volume limits track 24-hour trading volume per address, preventing wash trading or circular trading to manipulate market statistics. Circuit breakers monitor for extreme price movements (typically 20%+ in single trades) and automatically halt trading, requiring manual admin intervention to resume. This protects against oracle manipulation, flash loan attacks, or coordinated market manipulation attempts, though it introduces centralization risks around who controls circuit breaker resolution.

## Comparing LMSR to alternative mechanisms

Constant Product Market Makers (CPMM), specifically the Fixed Product Market Maker (FPMM) variant adapted for prediction markets, implement the simple invariant **x × y = k** where x and y represent YES and NO token reserves. Price calculation follows **p_yes = y/(x+y)**, ensuring prices sum exactly to 1. Gnosis's FPMM implementation has seen widespread adoption precisely because it requires only elementary arithmetic—no logarithms or exponentials needed. This translates to approximately **20,000 gas savings per trade** compared to LMSR (120,000 versus 150,000 gas), and dramatically simpler implementation with lower audit surface area. FPMM supports user liquidity provision naturally, allowing anyone to add capital in exchange for LP tokens, similar to Uniswap. This enables sustainable economics through fee collection, whereas pure LMSR requires either subsidization or guaranteed losses.

The critical trade-off involves Loss-vs-Rebalancing (LVR) at price extremes. Recent research from Paradigm demonstrates that **CPMM suffers 3-5x higher LVR than optimal mechanisms when prices approach 0 or 1**. At balanced prices around 50%, CPMM performs well, but as events become increasingly certain, the uniform liquidity distribution becomes inefficient. LMSR performs slightly better at extremes but still shows 2-4x higher LVR than theoretical optimum. Both mechanisms struggle with the same fundamental issue: they don't concentrate liquidity where volatility is highest. Despite this theoretical weakness, **CPMM's practical advantages have driven adoption** across Gnosis (offering both LMSR and FPMM), Polkamarkets, and numerous smaller platforms. The simplicity, gas efficiency, and ability to crowdsource liquidity outweigh LVR disadvantages for most real-world applications.

Liquidity-Sensitive LMSR (LS-LMSR) theoretically dominates both LMSR and CPMM by implementing **dynamic liquidity scaling via b(q) = α × Σqi**. This eliminates guaranteed losses, enables operator profit, and automatically adjusts depth to trading volume without manual tuning. Academic analysis proves superior performance characteristics, particularly for unbalanced markets where traditional LMSR requires excessive capital. The critical disadvantage: **price sums range from 1 to 1 + αn×ln(n) rather than exactly 1**, breaking direct probability interpretation. For binary markets with α = 0.05, prices sum between 1.00 and 1.07, requiring normalization for user display. Despite strong academic endorsement since 2013 and explicit recommendations that Augur and Gnosis implement it, **no major platform has deployed LS-LMSR in production**. This gap between theory and practice suggests either hidden implementation costs, user experience concerns around non-normalized prices, or insufficient improvement over simpler alternatives to justify additional complexity.

The pm-AMM mechanism published by Paradigm in November 2024 represents cutting-edge research optimized specifically for prediction markets with Gaussian score dynamics (sports scores, election margins, asset prices). It **achieves uniform LVR across all price levels**, eliminating the extreme-price inefficiency plaguing CPMM and LMSR. The static variant maintains constant LVR at any time, while the dynamic variant reduces liquidity over time to maintain constant expected LVR throughout market duration. Performance analysis shows pm-AMM delivering 50-70% lower losses than CPMM or LMSR at extreme prices while maintaining comparable performance at balanced prices. However, **zero production deployments exist** as of late 2024, no reference implementations are available, and the mechanism's novelty introduces unknown practical challenges. For bleeding-edge projects willing to pioneer new territory, pm-AMM offers theoretically superior performance, but conservative implementations should wait for proven track records.

Hybrid order book systems combine AMM base liquidity with off-chain order matching. Polymarket's architecture demonstrates this at scale: a Central Limit Order Book (CLOB) handles order matching off-chain with zero gas cost, while smart contracts settle matched trades on-chain. This delivers the best liquidity (professional market makers provide depth), tightest spreads (competition between limit orders), and highest scalability (processing thousands of orders before settlement). Polymarket achieved **over $2 billion in volume during October 2024**, thoroughly dominating the prediction market landscape. The architecture requires significant infrastructure investment—off-chain matching engines, order book maintenance, market maker APIs, and sophisticated risk management—making it suitable primarily for high-volume platforms with dedicated engineering resources. It also introduces centralization risks around off-chain components, though on-chain settlement preserves custody security.

Decision criteria for mechanism selection depend primarily on scale, technical resources, and user sophistication. **For most binary prediction markets in 2025, CPMM/FPMM represents the optimal starting point**: proven contracts (Gnosis conditional-tokens-market-makers), simplest implementation (lowest development cost), gas efficiency (important for user experience), and sustainable economics (user LP provision). Teams should choose LMSR only for play-money markets or academic contexts where subsidization is acceptable. LS-LMSR suits ambitious teams willing to implement novel mechanisms for automatic liquidity scaling, though requiring custom development without reference implementations. Hybrid order book architectures suit high-volume platforms expecting $10M+ in monthly volume, where infrastructure investment pays off through superior execution quality. The pm-AMM mechanism remains firmly in research territory for 2025, with teams advised to monitor developments but defer implementation until production-proven.

## Gas costs reveal implementation feasibility

Typical gas consumption on Ethereum mainnet shows LMSR trades costing **100,000-150,000 gas**, translating to $4-8 at $2,000 ETH and 20 gwei gas price. This breaks down as 21,000 gas for base transaction cost, 23,000 gas for token transfer from the user, 25,000 gas for LMSR calculation (exponentials and logarithms), 23,000 gas for token minting, 15,000 gas for storage updates, and 3,000 gas for event emissions. Market creation requires **200,000-400,000 gas** ($5-20), while resolution takes **80,000-120,000 gas** ($2-6), and settlement/claiming consumes **60,000-100,000 gas** ($1.50-5). These costs position LMSR competitively against Uniswap V2 (127,000 gas per swap) and slightly better than Uniswap V3 (150,000-180,000 gas), though CPMM alternatives run approximately 20,000 gas cheaper.

Optimization techniques deliver dramatic improvements. **Storage packing reduces gas costs by 60%** by compressing five storage slots into two through careful variable sizing—using uint128 for the liquidity parameter, uint64 for timestamps, and bool for flags allows multiple values to share slots at 20,000 gas savings each. Custom errors save 90% versus require strings by replacing 50-gas-per-character error messages with 24-gas error codes. Memory caching prevents repeated SLOADs by reading storage once into memory variables, saving 2,100 gas per avoided storage read since MLOAD costs only 3 gas. Unchecked math blocks save approximately 20 gas per arithmetic operation when overflow is mathematically impossible, particularly useful in loop counters. Batch operations amortize the 21,000 gas base transaction cost across multiple trades, saving gas proportionally for each additional operation in the batch.

Layer 2 deployment transforms economics entirely. Polygon, Arbitrum, Optimism, and other L2s reduce gas costs by **95-99%** compared to Ethereum mainnet, making per-trade costs pennies rather than dollars. Augur Turbo's migration to Polygon enabled ~$0.01 per trade, completely eliminating gas as a user friction point. Polymarket operates on Polygon for similar reasons, achieving the liquidity and volume necessary to dominate the space. For new prediction market launches in 2025, **deploying on L2 is essentially mandatory** for competitive user experience, with mainnet deployment reserved for settlement or high-value markets where security premiums justify the cost. The trade-off involves slightly reduced security versus Ethereum mainnet's consensus, though major L2s have proven robust enough for billion-dollar protocols.

## Building for raffle-triggered prediction markets

A production implementation for raffle-triggered binary markets should use the factory pattern with FPMM initially, planning migration to hybrid architecture as volume scales. The MarketFactory contract receives funding from the raffle system when participation crosses the threshold, automatically deploying an individual market instance with appropriate liquidity parameters. For binary markets expecting moderate activity (100-1000 trades), **initial funding of $100-200 translates to b ≈ 70-140** using the relationship b = F / ln(2). This provides meaningful liquidity while keeping treasury capital requirements manageable across dozens or hundreds of simultaneous markets.

Contract architecture should separate concerns with MarketFactory for deployment and registry, LMSRMarketMaker or FPMMMarketMaker for pricing logic (choose based on mechanism preference), ConditionalTokens for outcome token management (use Gnosis's proven implementation), OracleAdapter for resolution integration (UMA Optimistic Oracle for flexibility), and AccessControl for permissions. The raffle integration point implements a callback function like onRaffleThresholdReached that verifies the caller is the authorized raffle contract, confirms funding availability, creates the market through the factory, and emits events for off-chain indexing. Include rate limiting to prevent spam and ensure atomic operations so market creation either fully succeeds or fully reverts.

Security considerations demand multiple layers of protection. Implement front-running defense through mandatory maxPrice parameters on all trades, rejecting transactions if execution prices exceed user-specified thresholds. Add timestamp deadlines so transactions expire if not mined quickly, preventing execution long after submission when market conditions have changed. Consider commit-reveal schemes for large trades if front-running becomes problematic. Include circuit breakers that automatically pause markets when detecting anomalous price movements (20%+ in single transactions), requiring admin intervention to resume. Enforce trade size limits as a percentage of total liquidity (10% maximum) to prevent market manipulation through overwhelming single trades.

Gas optimization should focus on the highest-impact techniques: pack market state into minimal storage slots (2-3 slots for all state saves 40,000-60,000 gas), use custom errors exclusively instead of require strings (saves ~1,000 gas per error), cache storage in memory for calculations (saves 2,000+ gas per trade), implement unchecked math in loops and overflow-safe operations (saves 20 gas per operation), and deploy to Polygon or Arbitrum for 95%+ gas cost reduction. The complete system should target under 150,000 gas per trade on L2 (costing ~$0.01-0.05), under 300,000 gas per market creation, and under 100,000 gas per settlement.

## Beyond LMSR: the surprising evolution toward simplicity

The prediction market mechanism landscape has evolved in an unexpected direction—**away from theoretically sophisticated LMSR toward simpler alternatives**. This reveals a critical insight: mathematical elegance and bounded loss guarantees matter less than capital efficiency, implementation simplicity, and sustainable economics. Augur's migration from LMSR to Balancer pools, Polymarket's transition to order books, and Gnosis's addition of FPMM options all tell the same story. Pure LMSR survives primarily in play-money contexts (corporate prediction markets, academic research platforms) where guaranteed losses are acceptable subsidies for information discovery.

The unfulfilled promise of LS-LMSR deserves particular attention. Despite solving LMSR's capital inefficiency and enabling profitable operation, despite strong academic endorsement over more than a decade, and despite explicit recommendations to major platforms, **no significant deployment has occurred**. This suggests either that the complexity of non-normalized prices creates unacceptable user experience problems, or that the practical improvement over CPMM doesn't justify custom implementation when battle-tested alternatives exist. Future builders might succeed where others hesitated, particularly if they develop excellent UI/UX that hides price normalization complexity, but the track record suggests caution.

The most promising path forward combines FPMM for initial launch (leveraging Gnosis contracts, accepting FPMM's limitations), rapid deployment to L2 for gas efficiency (essential for competitive user experience), fee mechanisms for sustainability (1-2% trading fees supporting operations), and a planned migration to hybrid architecture as volume scales (adding order book functionality when monthly volume exceeds $10M+). This staged approach minimizes initial risk and development cost while providing clear scaling paths proven by successful platforms. Teams willing to pioneer novel mechanisms might implement LS-LMSR or pm-AMM, but should have strong technical capabilities and tolerance for operating without reference implementations or established best practices.

The raffle-triggered prediction market use case has specific implications. Since markets are created programmatically based on participation thresholds, **each market receives known funding amounts**, enabling precise liquidity parameter calculation. The treasury can set target b values based on expected market activity (b = 50-100 for typical markets), automatically funding each market at the appropriate level. Since markets are system-generated rather than user-created, implementing consistent liquidity levels becomes straightforward, avoiding the variable quality problem that platforms with user-generated markets face. This controlled environment actually favors LMSR over alternatives since the subsidization concern (markets might lose money) is offset by the known, bounded maximum loss that treasury planning can accommodate. However, the capital efficiency argument still suggests FPMM may be superior unless play-money mechanics make subsidy acceptable.

## Recommendations for immediate implementation

Start with Gnosis FPMM deployed on Polygon or Arbitrum, using their conditional-tokens-market-makers repository as foundation. This provides battle-tested contracts, comprehensive documentation, and a proven track record while minimizing gas costs through L2 deployment. Fund binary markets with $100-150 each, creating reasonable liquidity for expected trade volumes. Implement 1-2% trading fees split between treasury and potential future governance token holders, establishing sustainable economics from day one. Integrate UMA Optimistic Oracle V3 for market resolution, accepting the 2-hour liveness period as acceptable for most prediction markets where immediate resolution isn't critical.

Build your architecture with clear upgrade paths. The factory pattern enables deploying new market versions alongside old ones without migrating existing markets. Plan to add limit order functionality after 6 months once basic trading works smoothly and you understand user behavior. Consider implementing LS-LMSR or pm-AMM for specific high-value markets as experiments, comparing performance against baseline FPMM markets to gather empirical data. If monthly volume exceeds $10M across all markets, begin developing hybrid architecture with off-chain order matching, as this threshold justifies the infrastructure investment.

Focus optimization efforts on the highest-impact changes: storage packing in market state structs, custom errors throughout, aggressive caching of storage reads, and unchecked math where safe. Target 120,000 gas per trade on L2 (comparable to Uniswap V2), keeping user costs under $0.05 per transaction. Implement comprehensive slippage protection via maxPrice parameters and transaction deadlines, ensuring users cannot be front-run without transaction reversion. Deploy circuit breakers for extreme price movements but pair them with automated recovery mechanisms to prevent permanent halts requiring manual intervention.

The prediction market space remains surprisingly open for innovation despite existing platforms. LMSR's theoretical elegance provides bounded losses perfect for treasury budgeting, but its practical limitations have driven successful platforms toward simpler alternatives. Your raffle-triggered prediction market system can succeed by choosing proven mechanisms, optimizing relentlessly for user experience, and building clear scaling paths as volume grows. The future likely belongs to hybrid architectures combining AMM base liquidity with professional market making, but launching quickly with FPMM establishes market presence while learning user needs that inform future architectural decisions.
